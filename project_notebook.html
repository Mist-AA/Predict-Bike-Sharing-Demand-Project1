<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>af7bead7128c4372af74b6602c9decd4</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="predict-bike-sharing-demand-with-autogluon-template"
class="cell markdown" id="QXVd5E7gFdTW">
<h1>Predict Bike Sharing Demand with AutoGluon Template</h1>
</section>
<section id="project-predict-bike-sharing-demand-with-autogluon"
class="cell markdown" id="vdDL_6htFdTe">
<h2>Project: Predict Bike Sharing Demand with AutoGluon</h2>
<p>This notebook is a template with each step that you need to complete
for the project.</p>
<p>Please fill in your code where there are explicit <code>?</code>
markers in the notebook. You are welcome to add more cells and code as
you see fit.</p>
<p>Once you have completed all the code implementations, please export
your notebook as a HTML file so the reviews can view your code. Make
sure you have all outputs correctly outputted.</p>
<p><code>File-&gt; Export Notebook As... -&gt; Export Notebook as HTML</code></p>
<p>There is a writeup to complete as well after all code implememtation
is done. Please answer all questions and attach the necessary tables and
charts. You can complete the writeup in either markdown or PDF.</p>
<p>Completing the code template and writeup template will cover all of
the rubric points for this project.</p>
<p>The rubric contains "Stand Out Suggestions" for enhancing the project
beyond the minimum requirements. The stand out suggestions are optional.
If you decide to pursue the "stand out suggestions", you can include the
code in this notebook and also discuss the results in the writeup
file.</p>
</section>
<section id="step-1-create-an-account-with-kaggle" class="cell markdown"
id="CKr1mKWtFdTf">
<h2>Step 1: Create an account with Kaggle</h2>
</section>
<section id="create-kaggle-account-and-download-api-key"
class="cell markdown" id="68MEDy5oFdTh">
<h3>Create Kaggle Account and download API key</h3>
<p>Below is example of steps to get the API username and key. Each
student will have their own username and key.</p>
</section>
<div class="cell markdown" id="_fGZfmlxFdTi">
<ol>
<li>Open account settings. <span class="image placeholder"
data-original-image-src="kaggle1.png"
data-original-image-title="">kaggle1.png</span> <span
class="image placeholder" data-original-image-src="kaggle2.png"
data-original-image-title="">kaggle2.png</span></li>
<li>Scroll down to API and click Create New API Token. <span
class="image placeholder" data-original-image-src="kaggle3.png"
data-original-image-title="">kaggle3.png</span> <span
class="image placeholder" data-original-image-src="kaggle4.png"
data-original-image-title="">kaggle4.png</span></li>
<li>Open up <code>kaggle.json</code> and use the username and key. <span
class="image placeholder" data-original-image-src="kaggle5.png"
data-original-image-title="">kaggle5.png</span></li>
</ol>
</div>
<section
id="step-2-download-the-kaggle-dataset-using-the-kaggle-python-library"
class="cell markdown" id="PgRhs8whFdTj">
<h2>Step 2: Download the Kaggle dataset using the kaggle python
library</h2>
</section>
<section id="open-up-sagemaker-studio-and-use-starter-template"
class="cell markdown" id="3tl6GPF3FdTj">
<h3>Open up Sagemaker Studio and use starter template</h3>
</section>
<div class="cell markdown" id="Rt8z_nxSFdTo">
<ol>
<li>Notebook should be using a <code>ml.t3.medium</code> instance (2
vCPU + 4 GiB)</li>
<li>Notebook should be using kernal:
<code>Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)</code></li>
</ol>
</div>
<section id="install-packages" class="cell markdown" id="R7svkmZyFdTp">
<h3>Install packages</h3>
</section>
<div class="cell code" data-execution_count="1"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="TAwWK4YlFdTq" data-outputId="d0b9192c-67e4-4524-aaad-fb857c7b155d">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U pip</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U setuptools wheel</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U <span class="st">&quot;mxnet&lt;2.0.0&quot;</span> bokeh<span class="op">==</span><span class="fl">2.0.1</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install autogluon <span class="op">--</span>no<span class="op">-</span>cache<span class="op">-</span><span class="bu">dir</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Without --no-cache-dir, smaller aws instances may have trouble installing</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)
Collecting setuptools
  Downloading setuptools-67.8.0-py3-none-any.whl (1.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 18.7 MB/s eta 0:00:00
ent already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.40.0)
Installing collected packages: setuptools
  Attempting uninstall: setuptools
    Found existing installation: setuptools 67.7.2
    Uninstalling setuptools-67.7.2:
      Successfully uninstalled setuptools-67.7.2
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
ipython 7.34.0 requires jedi&gt;=0.16, which is not installed.
Successfully installed setuptools-67.8.0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb3"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;pip_warning&quot;</span><span class="fu">:{</span><span class="dt">&quot;packages&quot;</span><span class="fu">:</span><span class="ot">[</span><span class="st">&quot;_distutils_hack&quot;</span><span class="ot">,</span><span class="st">&quot;pkg_resources&quot;</span><span class="ot">,</span><span class="st">&quot;setuptools&quot;</span><span class="ot">]</span><span class="fu">}}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting mxnet&lt;2.0.0
  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.1/49.1 MB 19.9 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 140.2 MB/s eta 0:00:00
etadata (setup.py) ... ent already satisfied: PyYAML&gt;=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (6.0)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (2.8.2)
Requirement already satisfied: Jinja2&gt;=2.7 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (3.1.2)
Requirement already satisfied: numpy&gt;=1.11.3 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (1.22.4)
Requirement already satisfied: pillow&gt;=4.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (8.4.0)
Requirement already satisfied: packaging&gt;=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (23.1)
Requirement already satisfied: tornado&gt;=5 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (6.3.1)
Requirement already satisfied: typing_extensions&gt;=3.7.4 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (4.5.0)
Requirement already satisfied: requests&lt;3,&gt;=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet&lt;2.0.0) (2.27.1)
Collecting graphviz&lt;0.9.0,&gt;=0.8.1 (from mxnet&lt;2.0.0)
  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2&gt;=2.7-&gt;bokeh==2.0.1) (2.1.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.1-&gt;bokeh==2.0.1) (1.16.0)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (1.26.15)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (3.4)
Building wheels for collected packages: bokeh
  Building wheel for bokeh (setup.py) ... e=bokeh-2.0.1-py3-none-any.whl size=9080019 sha256=f92ae3c70165a841e272153498cc22d791ce42e9458fdfcf9a050cfa93d02913
  Stored in directory: /root/.cache/pip/wheels/be/b4/d8/7ce778fd6e637bea03a561223a77ba6649aff8168e3c613754
Successfully built bokeh
Installing collected packages: graphviz, mxnet, bokeh
  Attempting uninstall: graphviz
    Found existing installation: graphviz 0.20.1
    Uninstalling graphviz-0.20.1:
      Successfully uninstalled graphviz-0.20.1
  Attempting uninstall: bokeh
    Found existing installation: bokeh 2.4.3
    Uninstalling bokeh-2.4.3:
      Successfully uninstalled bokeh-2.4.3
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
panel 0.14.4 requires bokeh&lt;2.5.0,&gt;=2.4.0, but you have bokeh 2.0.1 which is incompatible.
Successfully installed bokeh-2.0.1 graphviz-0.8.4 mxnet-1.9.1
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting autogluon
  Downloading autogluon-0.7.0-py3-none-any.whl (9.7 kB)
Collecting autogluon.core[all]==0.7.0 (from autogluon)
  Downloading autogluon.core-0.7.0-py3-none-any.whl (218 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 218.3/218.3 kB 7.6 MB/s eta 0:00:00
 autogluon)
  Downloading autogluon.features-0.7.0-py3-none-any.whl (60 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.1/60.1 kB 212.9 MB/s eta 0:00:00
 autogluon)
  Downloading autogluon.tabular-0.7.0-py3-none-any.whl (292 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 292.2/292.2 kB 34.0 MB/s eta 0:00:00
ultimodal==0.7.0 (from autogluon)
  Downloading autogluon.multimodal-0.7.0-py3-none-any.whl (331 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 331.1/331.1 kB 186.9 MB/s eta 0:00:00
eseries[all]==0.7.0 (from autogluon)
  Downloading autogluon.timeseries-0.7.0-py3-none-any.whl (108 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 108.7/108.7 kB 163.0 MB/s eta 0:00:00
ent already satisfied: numpy&lt;1.27,&gt;=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.22.4)
Requirement already satisfied: scipy&lt;1.12,&gt;=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.10.1)
Requirement already satisfied: scikit-learn&lt;1.3,&gt;=1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.2.2)
Collecting networkx&lt;3.0,&gt;=2.3 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 123.8 MB/s eta 0:00:00
ent already satisfied: pandas&lt;1.6,&gt;=1.4.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.5.3)
Requirement already satisfied: tqdm&lt;5,&gt;=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (4.65.0)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (2.27.1)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (3.7.1)
Collecting boto3&lt;2,&gt;=1.10 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading boto3-1.26.151-py3-none-any.whl (135 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 128.9 MB/s eta 0:00:00
mon==0.7.0 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading autogluon.common-0.7.0-py3-none-any.whl (45 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.0/45.0 kB 273.0 MB/s eta 0:00:00
ent already satisfied: hyperopt&lt;0.2.8,&gt;=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (0.2.7)
Collecting ray[tune]&lt;2.3,&gt;=2.2 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading ray-2.2.0-cp310-cp310-manylinux2014_x86_64.whl (57.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.4/57.4 MB 260.2 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 297.2 MB/s eta 0:00:00
a&lt;4.18,&gt;=4.14 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.4/90.4 kB 276.1 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading seqeval-1.2.2.tar.gz (43 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 184.4 MB/s eta 0:00:00
etadata (setup.py) ...  autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.9/72.9 kB 329.3 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.7/199.7 kB 340.5 MB/s eta 0:00:00
m&lt;0.7.0,&gt;=0.6.12 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading timm-0.6.13-py3-none-any.whl (549 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 549.1/549.1 kB 412.2 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 887.5/887.5 MB 225.8 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.2/24.2 MB 235.2 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading fairscale-0.4.13.tar.gz (266 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 266.3/266.3 kB 214.7 MB/s eta 0:00:00
ents to build wheel ... etadata (pyproject.toml) ... ent already satisfied: scikit-image&lt;0.20.0,&gt;=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.19.3)
Collecting pytorch-lightning&lt;1.10.0,&gt;=1.9.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 829.5/829.5 kB 373.2 MB/s eta 0:00:00
ent already satisfied: text-unidecode&lt;1.4,&gt;=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (1.3)
Collecting torchmetrics&lt;0.9.0,&gt;=0.8.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 409.8/409.8 kB 401.7 MB/s eta 0:00:00
ers&lt;4.27.0,&gt;=4.23.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 257.9 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)
Collecting omegaconf&lt;2.3.0,&gt;=2.1.1 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.3/79.3 kB 307.7 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 419.3 MB/s eta 0:00:00
etric-learning&lt;2.0,&gt;=1.3.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pytorch_metric_learning-1.7.3-py3-none-any.whl (112 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 112.2/112.2 kB 357.5 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.5/410.5 kB 363.3 MB/s eta 0:00:00
ent already satisfied: nltk&lt;4.0.0,&gt;=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (3.8.1)
Collecting openmim&lt;0.4.0,&gt;0.1.5 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading openmim-0.3.7-py2.py3-none-any.whl (51 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.3/51.3 kB 269.0 MB/s eta 0:00:00
ent already satisfied: defusedxml&lt;0.7.2,&gt;=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.7.1)
Requirement already satisfied: jinja2&lt;3.2,&gt;=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (3.1.2)
Requirement already satisfied: tensorboard&lt;3,&gt;=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (2.12.2)
Collecting pytesseract&lt;0.3.11,&gt;=0.3.9 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)
Collecting catboost&lt;1.2,&gt;=1.0 (from autogluon.tabular[all]==0.7.0-&gt;autogluon)
  Downloading catboost-1.1.1-cp310-none-manylinux1_x86_64.whl (76.6 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.6/76.6 MB 236.2 MB/s eta 0:00:00
ent already satisfied: lightgbm&lt;3.4,&gt;=3.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.3.5)
Requirement already satisfied: xgboost&lt;1.8,&gt;=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.7.5)
Requirement already satisfied: fastai&lt;2.8,&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.7.12)
Requirement already satisfied: joblib&lt;2,&gt;=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.2.0)
Requirement already satisfied: statsmodels&lt;0.14,&gt;=0.13.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.13.5)
Collecting gluonts&lt;0.13,&gt;=0.12.0 (from autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading gluonts-0.12.8-py3-none-any.whl (1.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 423.8 MB/s eta 0:00:00
 autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading statsforecast-1.4.0-py3-none-any.whl (91 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.0/92.0 kB 280.4 MB/s eta 0:00:00
 autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading ujson-5.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.9/53.9 kB 247.5 MB/s eta 0:00:00
e&lt;0.16,&gt;=0.14 (from autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading sktime-0.15.1-py3-none-any.whl (16.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.0/16.0 MB 243.3 MB/s eta 0:00:00
 autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading tbats-1.1.3-py3-none-any.whl (44 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.0/44.0 kB 191.3 MB/s eta 0:00:00
darima&lt;1.9,&gt;=1.8.2 (from autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading pmdarima-1.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 181.5 MB/s eta 0:00:00
ent already satisfied: psutil&lt;6,&gt;=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (5.9.5)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (67.8.0)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate&lt;0.17,&gt;=0.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (23.1)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate&lt;0.17,&gt;=0.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (6.0)
Collecting botocore&lt;1.30.0,&gt;=1.29.151 (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading botocore-1.29.151-py3-none-any.whl (10.9 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.9/10.9 MB 177.4 MB/s eta 0:00:00
espath&lt;2.0.0,&gt;=0.7.1 (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)
Collecting s3transfer&lt;0.7.0,&gt;=0.6.0 (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 166.5 MB/s eta 0:00:00
ent already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.8.4)
Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (5.13.1)
Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.16.0)
Collecting datasets&gt;=2.0.0 (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 474.6/474.6 kB 109.7 MB/s eta 0:00:00
 evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading dill-0.3.6-py3-none-any.whl (110 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 240.9 MB/s eta 0:00:00
 evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.5/212.5 kB 330.0 MB/s eta 0:00:00
ultiprocess (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.3/134.3 kB 210.1 MB/s eta 0:00:00
ent already satisfied: fsspec[http]&gt;=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2023.4.0)
Collecting huggingface-hub&gt;=0.7.0 (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 236.8/236.8 kB 240.4 MB/s eta 0:00:00
 evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading responses-0.18.0-py3-none-any.whl (38 kB)
Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (23.1.2)
Requirement already satisfied: fastdownload&lt;2,&gt;=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.0.7)
Requirement already satisfied: fastcore&lt;1.6,&gt;=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.5.29)
Requirement already satisfied: fastprogress&gt;=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.3)
Requirement already satisfied: spacy&lt;4 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.5.2)
Requirement already satisfied: pydantic~=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.10.7)
Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.12.0)
Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (4.5.0)
Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.18.3)
Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.2.1)
Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.10.9.7)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2&lt;3.2,&gt;=3.0.3-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.1.2)
Requirement already satisfied: attrs&gt;=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema&lt;4.18,&gt;=4.14-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (23.1.0)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema&lt;4.18,&gt;=4.14-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.19.3)
Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm&lt;3.4,&gt;=3.3-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.40.0)
Requirement already satisfied: gdown&gt;=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.6.6)
Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk&lt;4.0.0,&gt;=3.4.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (8.1.3)
Requirement already satisfied: regex&gt;=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk&lt;4.0.0,&gt;=3.4.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2022.10.31)
Collecting antlr4-python3-runtime==4.9.* (from omegaconf&lt;2.3.0,&gt;=2.1.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.0/117.0 kB 351.3 MB/s eta 0:00:00
etadata (setup.py) ... a (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)
Collecting model-index (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)
Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (13.3.4)
Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.8.10)
Requirement already satisfied: python-dateutil&gt;=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas&lt;1.6,&gt;=1.4.1-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas&lt;1.6,&gt;=1.4.1-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2022.7.1)
Requirement already satisfied: Cython!=0.29.18,&gt;=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima&lt;1.9,&gt;=1.8.2-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.29.34)
Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima&lt;1.9,&gt;=1.8.2-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.26.15)
Collecting lightning-utilities&gt;=0.6.0.post0 (from pytorch-lightning&lt;1.10.0,&gt;=1.9.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.12.0)
Requirement already satisfied: msgpack&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.0.5)
Requirement already satisfied: protobuf!=3.19.5,&gt;=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.20.3)
Collecting aiosignal (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Collecting frozenlist (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 149.6/149.6 kB 339.9 MB/s eta 0:00:00
 ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading virtualenv-20.23.0-py3-none-any.whl (3.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 278.3 MB/s eta 0:00:00
ent already satisfied: grpcio&gt;=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.54.0)
Collecting tensorboardX&gt;=1.9 (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 282.6 MB/s eta 0:00:00
ent already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.4)
Requirement already satisfied: imageio&gt;=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.25.1)
Requirement already satisfied: tifffile&gt;=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2023.4.12)
Requirement already satisfied: PyWavelets&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.4.1)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn&lt;1.3,&gt;=1.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.1.0)
Collecting deprecated&gt;=1.2.13 (from sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)
Requirement already satisfied: numba&gt;=0.55 in /usr/local/lib/python3.10/dist-packages (from sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.56.4)
Requirement already satisfied: patsy&gt;=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels&lt;0.14,&gt;=0.13.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.5.3)
Requirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.4.0)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.17.3)
Requirement already satisfied: google-auth-oauthlib&lt;1.1,&gt;=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.0.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.4.3)
Requirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.7.0)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.8.1)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.3.0)
Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 849.3/849.3 kB 437.5 MB/s eta 0:00:00
 torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 557.1/557.1 MB 235.4 MB/s eta 0:00:00
 torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 317.1/317.1 MB 213.2 MB/s eta 0:00:00
 torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.0/21.0 MB 247.6 MB/s eta 0:00:00
 torchmetrics&lt;0.9.0,&gt;=0.8.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)
Collecting tokenizers!=0.11.3,&lt;0.14,&gt;=0.11.1 (from transformers&lt;4.27.0,&gt;=4.23.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 260.7 MB/s eta 0:00:00
ent already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.0.7)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (4.39.3)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.4.4)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.0.9)
Requirement already satisfied: pyarrow&gt;=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (9.0.0)
Collecting aiohttp (from datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 459.3 MB/s eta 0:00:00
ent already satisfied: wrapt&lt;2,&gt;=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated&gt;=1.2.13-&gt;sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.14.1)
Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown&gt;=4.0.0-&gt;nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.11.2)
Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (5.3.0)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.3.0)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.9)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.3.1)
Requirement already satisfied: llvmlite&lt;0.40,&gt;=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba&gt;=0.55-&gt;sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.39.1)
Requirement already satisfied: spacy-legacy&lt;3.1.0,&gt;=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.0.12)
Requirement already satisfied: spacy-loggers&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.4)
Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.9)
Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.0.7)
Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.0.8)
Requirement already satisfied: thinc&lt;8.2.0,&gt;=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (8.1.9)
Requirement already satisfied: wasabi&lt;1.2.0,&gt;=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.1.1)
Requirement already satisfied: srsly&lt;3.0.0,&gt;=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.4.6)
Requirement already satisfied: catalogue&lt;2.1.0,&gt;=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.0.8)
Requirement already satisfied: typer&lt;0.8.0,&gt;=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.7.0)
Requirement already satisfied: pathy&gt;=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.10.1)
Requirement already satisfied: smart-open&lt;7.0.0,&gt;=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (6.3.0)
Requirement already satisfied: langcodes&lt;4.0.0,&gt;=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.3.0)
Collecting distlib&lt;1,&gt;=0.3.6 (from virtualenv&gt;=20.0.24-&gt;ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 468.5/468.5 kB 272.7 MB/s eta 0:00:00
ent already satisfied: platformdirs&lt;4,&gt;=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv&gt;=20.0.24-&gt;ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.3.0)
Collecting ordered-set (from model-index-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)
Requirement already satisfied: tenacity&gt;=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly-&gt;catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (8.2.2)
Requirement already satisfied: markdown-it-py&lt;3.0.0,&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.2.0)
Requirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.14.0)
Collecting multidict&lt;7.0,&gt;=4.5 (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 198.7 MB/s eta 0:00:00
eout&lt;5.0,&gt;=4.0.0a3 (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)
Collecting yarl&lt;2.0,&gt;=1.0 (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 405.2 MB/s eta 0:00:00
ent already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&lt;3.0.0,&gt;=2.2.0-&gt;rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.1.2)
Requirement already satisfied: pyasn1&lt;0.6.0,&gt;=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.5.0)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.2.2)
Requirement already satisfied: blis&lt;0.8.0,&gt;=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.2.0,&gt;=8.1.8-&gt;spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.7.9)
Requirement already satisfied: confection&lt;1.0.0,&gt;=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.2.0,&gt;=8.1.8-&gt;spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.0.4)
Requirement already satisfied: soupsieve&gt;1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4-&gt;gdown&gt;=4.0.0-&gt;nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.4.1)
Requirement already satisfied: PySocks!=1.5.7,&gt;=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.7.1)
Building wheels for collected packages: fairscale, antlr4-python3-runtime, seqeval
  Building wheel for fairscale (pyproject.toml) ... e=fairscale-0.4.13-py3-none-any.whl size=332112 sha256=8bdd3e209236a0d64a40dfa8d71cb6b41e64c9f50ab9f974a3064f0911f9a869
  Stored in directory: /tmp/pip-ephem-wheel-cache-vdu2aghb/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3
  Building wheel for antlr4-python3-runtime (setup.py) ... e: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=4202fa73f7d3c021ac6a1a73ed0d3e9d2e239ec536dd2c0f961712aff6acdef3
  Stored in directory: /tmp/pip-ephem-wheel-cache-vdu2aghb/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88
  Building wheel for seqeval (setup.py) ... e=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=818df9a27a37c8cd010bf7fdaf11573f6450e5c2fc71d223e60c30e95b8ef3f7
  Stored in directory: /tmp/pip-ephem-wheel-cache-vdu2aghb/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa
Successfully built fairscale antlr4-python3-runtime seqeval
Installing collected packages: tokenizers, sentencepiece, distlib, antlr4-python3-runtime, xxhash, virtualenv, ujson, tensorboardX, pyDeprecate, Pillow, ordered-set, omegaconf, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nptyping, networkx, multidict, lightning-utilities, jsonschema, jmespath, frozenlist, dill, deprecated, colorama, async-timeout, yarl, responses, pytesseract, nvidia-cudnn-cu11, multiprocess, model-index, huggingface-hub, botocore, aiosignal, transformers, torch, seqeval, s3transfer, ray, openmim, gluonts, catboost, aiohttp, torchvision, torchmetrics, statsforecast, sktime, pytorch-metric-learning, pmdarima, nlpaug, fairscale, boto3, accelerate, timm, tbats, pytorch-lightning, datasets, autogluon.common, evaluate, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon
  Attempting uninstall: Pillow
    Found existing installation: Pillow 8.4.0
    Uninstalling Pillow-8.4.0:
      Successfully uninstalled Pillow-8.4.0
  Attempting uninstall: networkx
    Found existing installation: networkx 3.1
    Uninstalling networkx-3.1:
      Successfully uninstalled networkx-3.1
  Attempting uninstall: jsonschema
    Found existing installation: jsonschema 4.3.3
    Uninstalling jsonschema-4.3.3:
      Successfully uninstalled jsonschema-4.3.3
  Attempting uninstall: torch
    Found existing installation: torch 2.0.1+cu118
    Uninstalling torch-2.0.1+cu118:
      Successfully uninstalled torch-2.0.1+cu118
  Attempting uninstall: torchvision
    Found existing installation: torchvision 0.15.2+cu118
    Uninstalling torchvision-0.15.2+cu118:
      Successfully uninstalled torchvision-0.15.2+cu118
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
panel 0.14.4 requires bokeh&lt;2.5.0,&gt;=2.4.0, but you have bokeh 2.0.1 which is incompatible.
torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.
torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.
torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.
Successfully installed Pillow-9.5.0 accelerate-0.16.0 aiohttp-3.8.4 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 async-timeout-4.0.2 autogluon-0.7.0 autogluon.common-0.7.0 autogluon.core-0.7.0 autogluon.features-0.7.0 autogluon.multimodal-0.7.0 autogluon.tabular-0.7.0 autogluon.timeseries-0.7.0 boto3-1.26.151 botocore-1.29.151 catboost-1.1.1 colorama-0.4.6 datasets-2.12.0 deprecated-1.2.14 dill-0.3.6 distlib-0.3.6 evaluate-0.3.0 fairscale-0.4.13 frozenlist-1.3.3 gluonts-0.12.8 huggingface-hub-0.15.1 jmespath-1.0.1 jsonschema-4.17.3 lightning-utilities-0.8.0 model-index-0.1.11 multidict-6.0.4 multiprocess-0.70.14 networkx-2.8.8 nlpaug-1.1.11 nptyping-2.4.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 omegaconf-2.2.3 openmim-0.3.7 ordered-set-4.1.0 pmdarima-1.8.5 pyDeprecate-0.3.2 pytesseract-0.3.10 pytorch-lightning-1.9.5 pytorch-metric-learning-1.7.3 ray-2.2.0 responses-0.18.0 s3transfer-0.6.1 sentencepiece-0.1.99 seqeval-1.2.2 sktime-0.15.1 statsforecast-1.4.0 tbats-1.1.3 tensorboardX-2.6 timm-0.6.13 tokenizers-0.13.3 torch-1.13.1 torchmetrics-0.8.2 torchvision-0.14.1 transformers-4.26.1 ujson-5.8.0 virtualenv-20.23.0 xxhash-3.2.0 yarl-1.9.2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb5"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;pip_warning&quot;</span><span class="fu">:{</span><span class="dt">&quot;packages&quot;</span><span class="fu">:</span><span class="ot">[</span><span class="st">&quot;PIL&quot;</span><span class="ot">,</span><span class="st">&quot;pydevd_plugins&quot;</span><span class="ot">]</span><span class="fu">}}</span></span></code></pre></div>
</div>
</div>
<section id="setup-kaggle-api-key" class="cell markdown"
id="xUjCIm1zFdTt">
<h3>Setup Kaggle API Key</h3>
</section>
<div class="cell code" data-execution_count="2" id="D-qk4lVLFdTt">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create the .kaggle directory and an empty kaggle.json file</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>q Kaggle</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>mkdir <span class="op">-</span>p <span class="op">/</span>root<span class="op">/</span>.kaggle</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>touch <span class="op">/</span>root<span class="op">/</span>.kaggle<span class="op">/</span>kaggle.json</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>chmod <span class="dv">600</span> <span class="op">/</span>root<span class="op">/</span>.kaggle<span class="op">/</span>kaggle.json</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="5" id="g7sSgJrOFdTu">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fill in your user name and key from creating the kaggle account and API token file</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>kaggle_username <span class="op">=</span> <span class="st">&quot;ayushmaanagg&quot;</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>kaggle_key <span class="op">=</span> <span class="st">&quot;6f2ab639cac243c2bf64dc539f3f20b1&quot;</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Save API token the kaggle.json file</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&quot;/root/.kaggle/kaggle.json&quot;</span>, <span class="st">&quot;w&quot;</span>) <span class="im">as</span> f:</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    f.write(json.dumps({<span class="st">&quot;username&quot;</span>: kaggle_username, <span class="st">&quot;key&quot;</span>: kaggle_key}))</span></code></pre></div>
</div>
<section id="download-and-explore-dataset" class="cell markdown"
id="myStreNQFdTv">
<h3>Download and explore dataset</h3>
</section>
<section
id="go-to-the-bike-sharing-demand-competition-and-agree-to-the-terms"
class="cell markdown" id="aQ8XQm1hFdTv">
<h3>Go to the bike sharing demand competition and agree to the
terms</h3>
<p><span class="image placeholder" data-original-image-src="kaggle6.png"
data-original-image-title="">kaggle6.png</span></p>
</section>
<div class="cell code" data-execution_count="6"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="rOmYDGJBFdTv" data-outputId="31819d4f-3bc6-4675-beb1-cd72e5f5dc89">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the dataset, it will be in a .zip file so you&#39;ll need to unzip it as well.</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions download <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># If you already downloaded it you can use the -o command to overwrite the file</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>unzip <span class="op">-</span>o bike<span class="op">-</span>sharing<span class="op">-</span>demand.<span class="bu">zip</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Downloading bike-sharing-demand.zip to /content
  0% 0.00/189k [00:00&lt;?, ?B/s]
100% 189k/189k [00:00&lt;00:00, 82.6MB/s]
Archive:  bike-sharing-demand.zip
  inflating: sampleSubmission.csv    
  inflating: test.csv                
  inflating: train.csv               
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="7" id="jzeUIAcVFdTw">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> autogluon.tabular <span class="im">import</span> TabularPredictor</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="8"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="Bx136AAKFdTx" data-outputId="0bc4c8f3-8e4b-4f84-f3f1-a9e1638d9ee8">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the train dataset in pandas by reading the csv</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the parsing of the datetime column so you can use some of the `dt` features in pandas later</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> pd.read_csv(<span class="st">&quot;train.csv&quot;</span>,parse_dates<span class="op">=</span>[<span class="st">&quot;datetime&quot;</span>])</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>train.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="8">

  <div id="df-9d857ac4-2cbb-41f0-81e7-e03f8134ec15">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-01 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0</td>
      <td>3</td>
      <td>13</td>
      <td>16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-01 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>8</td>
      <td>32</td>
      <td>40</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-01 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>5</td>
      <td>27</td>
      <td>32</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-01 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>3</td>
      <td>10</td>
      <td>13</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-01 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-9d857ac4-2cbb-41f0-81e7-e03f8134ec15')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-9d857ac4-2cbb-41f0-81e7-e03f8134ec15 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-9d857ac4-2cbb-41f0-81e7-e03f8134ec15');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="9" id="maH7vN7FFdTx">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple output of the train dataset to view some of the min/max/varition of the dataset features.</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="10"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="gL96uqoDFdTy" data-outputId="400382d9-87a7-4316-b99c-5e4443a63599">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the test pandas dataframe in pandas by reading the csv, remember to parse the datetime!</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> pd.read_csv(<span class="st">&quot;test.csv&quot;</span>,parse_dates<span class="op">=</span>[<span class="st">&quot;datetime&quot;</span>])</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>test.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="10">

  <div id="df-5dc8581a-8a67-4a20-ad3f-9e9b596ad2bc">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-20 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>11.365</td>
      <td>56</td>
      <td>26.0027</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-20 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>13.635</td>
      <td>56</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-20 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>13.635</td>
      <td>56</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-20 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>12.880</td>
      <td>56</td>
      <td>11.0014</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-20 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>12.880</td>
      <td>56</td>
      <td>11.0014</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-5dc8581a-8a67-4a20-ad3f-9e9b596ad2bc')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-5dc8581a-8a67-4a20-ad3f-9e9b596ad2bc button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-5dc8581a-8a67-4a20-ad3f-9e9b596ad2bc');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="11"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}"
id="exNSmGLcFdTy" data-outputId="235adc2b-8b3b-42d0-b8e3-10267015cdf4">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same thing as train and test dataset</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>submission <span class="op">=</span> pd.read_csv(<span class="st">&quot;sampleSubmission.csv&quot;</span>,parse_dates<span class="op">=</span>[<span class="st">&quot;datetime&quot;</span>])</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>submission.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="11">

  <div id="df-1ef03a8e-86c1-4ba6-854a-4180fab26a54">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-20 00:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-20 01:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-20 02:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-20 03:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-20 04:00:00</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-1ef03a8e-86c1-4ba6-854a-4180fab26a54')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-1ef03a8e-86c1-4ba6-854a-4180fab26a54 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-1ef03a8e-86c1-4ba6-854a-4180fab26a54');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<section id="step-3-train-a-model-using-autogluons-tabular-prediction"
class="cell markdown" id="Clil3j2QFdTz">
<h2>Step 3: Train a model using AutoGluon’s Tabular Prediction</h2>
</section>
<div class="cell markdown" id="XcBt4QN4FdT0">
<p>Requirements:</p>
<ul>
<li>We are prediting <code>count</code>, so it is the label we are
setting.</li>
<li>Ignore <code>casual</code> and <code>registered</code> columns as
they are also not present in the test dataset.</li>
<li>Use the <code>root_mean_squared_error</code> as the metric to use
for evaluation.</li>
<li>Set a time limit of 10 minutes (600 seconds).</li>
<li>Use the preset <code>best_quality</code> to focus on creating the
best model.</li>
</ul>
</div>
<div class="cell code" data-execution_count="12"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="fRnkY0XlFdT1" data-outputId="03b2197e-22a2-4a5e-bea9-23ab0d6c8168">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>predictor <span class="op">=</span> TabularPredictor(label <span class="op">=</span> <span class="st">&#39;count&#39;</span>, </span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>                             eval_metric <span class="op">=</span> <span class="st">&#39;root_mean_squared_error&#39;</span>, </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>                             learner_kwargs <span class="op">=</span> {<span class="st">&#39;ignored_columns&#39;</span>: [<span class="st">&#39;casual&#39;</span>, <span class="st">&#39;registered&#39;</span>]}).fit(train_data <span class="op">=</span> train, </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>                                                                                                 time_limit <span class="op">=</span> <span class="dv">600</span>, </span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>                                                                                                 presets <span class="op">=</span> <span class="st">&#39;best_quality&#39;</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230611_111807/&quot;
Presets specified: [&#39;best_quality&#39;]
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230611_111807/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023
Train Data Rows:    10886
Train Data Columns: 11
Label Column: count
Preprocessing data ...
AutoGluon infers your prediction problem is: &#39;regression&#39; (because dtype of label-column == int and many unique label-values observed).
	Label info (max, min, mean, stddev): (977, 1, 191.57413, 181.14445)
	If &#39;regression&#39; is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: [&#39;binary&#39;, &#39;multiclass&#39;, &#39;regression&#39;])
Using Feature Generators to preprocess the data ...
Dropping user-specified ignored columns: [&#39;casual&#39;, &#39;registered&#39;]
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    11959.62 MB
	Train Data (Original)  Memory Usage: 0.78 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 2 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 5 | [&#39;season&#39;, &#39;holiday&#39;, &#39;workingday&#39;, &#39;weather&#39;, &#39;humidity&#39;]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 3 | [&#39;season&#39;, &#39;weather&#39;, &#39;humidity&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.1s = Fit runtime
	9 features in original data used to generate 13 features in processed data.
	Train Data (Processed) Memory Usage: 0.98 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.19s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
Fitting 11 L1 models ...
Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.77s of the 599.81s of remaining time.
	-101.5462	 = Validation score   (-root_mean_squared_error)
	0.05s	 = Training   runtime
	0.04s	 = Validation runtime
Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 394.68s of the 594.72s of remaining time.
	-84.1251	 = Validation score   (-root_mean_squared_error)
	0.05s	 = Training   runtime
	0.05s	 = Validation runtime
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 394.54s of the 594.58s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-131.4609	 = Validation score   (-root_mean_squared_error)
	59.03s	 = Training   runtime
	7.18s	 = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 326.97s of the 527.0s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-131.0542	 = Validation score   (-root_mean_squared_error)
	35.92s	 = Training   runtime
	1.94s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 287.71s of the 487.74s of remaining time.
	-116.5484	 = Validation score   (-root_mean_squared_error)
	8.46s	 = Training   runtime
	0.42s	 = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 278.03s of the 478.06s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-130.4855	 = Validation score   (-root_mean_squared_error)
	186.13s	 = Training   runtime
	0.1s	 = Validation runtime
Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 87.21s of the 287.24s of remaining time.
	-124.6007	 = Validation score   (-root_mean_squared_error)
	6.56s	 = Training   runtime
	0.55s	 = Validation runtime
Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 79.28s of the 279.31s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-137.8608	 = Validation score   (-root_mean_squared_error)
	82.11s	 = Training   runtime
	0.32s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 194.58s of remaining time.
	-84.1251	 = Validation score   (-root_mean_squared_error)
	0.64s	 = Training   runtime
	0.0s	 = Validation runtime
Fitting 9 L2 models ...
Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 193.92s of the 193.91s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-60.2649	 = Validation score   (-root_mean_squared_error)
	47.58s	 = Training   runtime
	3.52s	 = Validation runtime
Fitting model: LightGBM_BAG_L2 ... Training model for up to 142.14s of the 142.12s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-54.934	 = Validation score   (-root_mean_squared_error)
	25.61s	 = Training   runtime
	0.39s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 112.99s of the 112.97s of remaining time.
	-53.2867	 = Validation score   (-root_mean_squared_error)
	28.34s	 = Training   runtime
	0.48s	 = Validation runtime
Fitting model: CatBoost_BAG_L2 ... Training model for up to 83.72s of the 83.7s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-55.5609	 = Validation score   (-root_mean_squared_error)
	63.77s	 = Training   runtime
	0.05s	 = Validation runtime
Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 17.26s of the 17.25s of remaining time.
	-53.8551	 = Validation score   (-root_mean_squared_error)
	7.75s	 = Training   runtime
	0.72s	 = Validation runtime
Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 7.64s of the 7.63s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-91.3617	 = Validation score   (-root_mean_squared_error)
	32.23s	 = Training   runtime
	0.32s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -29.92s of remaining time.
	-52.7161	 = Validation score   (-root_mean_squared_error)
	0.24s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 630.19s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230611_111807/&quot;)
</code></pre>
</div>
</div>
<section
id="review-autogluons-training-run-with-ranking-of-models-that-did-the-best"
class="cell markdown" id="04ibCJVFFdT1">
<h3>Review AutoGluon's training run with ranking of models that did the
best.</h3>
</section>
<div class="cell code" data-execution_count="13"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="zQ5qjHCxFdT2" data-outputId="08ef5d6c-7633-4fab-e0ae-e492c5e16da0">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>predictor.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0      WeightedEnsemble_L3  -52.716107      12.193213  440.246144                0.000465           0.243481            3       True         16
1   RandomForestMSE_BAG_L2  -53.286673      11.080792  406.647108                0.481105          28.340273            2       True         12
2     ExtraTreesMSE_BAG_L2  -53.855148      11.317731  386.053022                0.718044           7.746187            2       True         14
3          LightGBM_BAG_L2  -54.933963      10.993599  403.916203                0.393912          25.609368            2       True         11
4          CatBoost_BAG_L2  -55.560858      10.647552  442.080469                0.047864          63.773634            2       True         13
5        LightGBMXT_BAG_L2  -60.264888      14.118723  425.884265                3.519036          47.577430            2       True         10
6    KNeighborsDist_BAG_L1  -84.125061       0.052344    0.048824                0.052344           0.048824            1       True          2
7      WeightedEnsemble_L2  -84.125061       0.054250    0.687518                0.001905           0.638694            2       True          9
8   NeuralNetFastAI_BAG_L2  -91.361718      10.923852  410.536867                0.324164          32.230032            2       True         15
9    KNeighborsUnif_BAG_L1 -101.546199       0.042998    0.053868                0.042998           0.053868            1       True          1
10  RandomForestMSE_BAG_L1 -116.548359       0.422114    8.459296                0.422114           8.459296            1       True          5
11    ExtraTreesMSE_BAG_L1 -124.600676       0.549188    6.556365                0.549188           6.556365            1       True          7
12         CatBoost_BAG_L1 -130.485451       0.102046  186.126971                0.102046         186.126971            1       True          6
13         LightGBM_BAG_L1 -131.054162       1.936704   35.923737                1.936704          35.923737            1       True          4
14       LightGBMXT_BAG_L1 -131.460909       7.178146   59.030051                7.178146          59.030051            1       True          3
15  NeuralNetFastAI_BAG_L1 -137.860780       0.316147   82.107723                0.316147          82.107723            1       True          8
Number of models trained: 16
Types of models trained:
{&#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_RF&#39;, &#39;StackerEnsembleModel_XT&#39;, &#39;StackerEnsembleModel_KNN&#39;, &#39;StackerEnsembleModel_LGB&#39;, &#39;StackerEnsembleModel_NNFastAiTabular&#39;, &#39;StackerEnsembleModel_CatBoost&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 3 | [&#39;season&#39;, &#39;weather&#39;, &#39;humidity&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="13">
<pre><code>{&#39;model_types&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_XT&#39;,
  &#39;NeuralNetFastAI_BAG_L1&#39;: &#39;StackerEnsembleModel_NNFastAiTabular&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L2&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;ExtraTreesMSE_BAG_L2&#39;: &#39;StackerEnsembleModel_XT&#39;,
  &#39;NeuralNetFastAI_BAG_L2&#39;: &#39;StackerEnsembleModel_NNFastAiTabular&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: -101.54619908446061,
  &#39;KNeighborsDist_BAG_L1&#39;: -84.12506123181602,
  &#39;LightGBMXT_BAG_L1&#39;: -131.46090891834504,
  &#39;LightGBM_BAG_L1&#39;: -131.054161598899,
  &#39;RandomForestMSE_BAG_L1&#39;: -116.54835939455667,
  &#39;CatBoost_BAG_L1&#39;: -130.48545133709007,
  &#39;ExtraTreesMSE_BAG_L1&#39;: -124.60067564699747,
  &#39;NeuralNetFastAI_BAG_L1&#39;: -137.86077972728603,
  &#39;WeightedEnsemble_L2&#39;: -84.12506123181602,
  &#39;LightGBMXT_BAG_L2&#39;: -60.264888437667366,
  &#39;LightGBM_BAG_L2&#39;: -54.93396306063684,
  &#39;RandomForestMSE_BAG_L2&#39;: -53.286673079524796,
  &#39;CatBoost_BAG_L2&#39;: -55.56085828850475,
  &#39;ExtraTreesMSE_BAG_L2&#39;: -53.85514845199492,
  &#39;NeuralNetFastAI_BAG_L2&#39;: -91.36171755582734,
  &#39;WeightedEnsemble_L3&#39;: -52.7161070924021},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_111807/models/KNeighborsUnif_BAG_L1/&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_111807/models/KNeighborsDist_BAG_L1/&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_111807/models/LightGBMXT_BAG_L1/&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_111807/models/LightGBM_BAG_L1/&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_111807/models/RandomForestMSE_BAG_L1/&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_111807/models/CatBoost_BAG_L1/&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_111807/models/ExtraTreesMSE_BAG_L1/&#39;,
  &#39;NeuralNetFastAI_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_111807/models/NeuralNetFastAI_BAG_L1/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230611_111807/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;AutogluonModels/ag-20230611_111807/models/LightGBMXT_BAG_L2/&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;AutogluonModels/ag-20230611_111807/models/LightGBM_BAG_L2/&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;AutogluonModels/ag-20230611_111807/models/RandomForestMSE_BAG_L2/&#39;,
  &#39;CatBoost_BAG_L2&#39;: &#39;AutogluonModels/ag-20230611_111807/models/CatBoost_BAG_L2/&#39;,
  &#39;ExtraTreesMSE_BAG_L2&#39;: &#39;AutogluonModels/ag-20230611_111807/models/ExtraTreesMSE_BAG_L2/&#39;,
  &#39;NeuralNetFastAI_BAG_L2&#39;: &#39;AutogluonModels/ag-20230611_111807/models/NeuralNetFastAI_BAG_L2/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230611_111807/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.05386805534362793,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.04882359504699707,
  &#39;LightGBMXT_BAG_L1&#39;: 59.03005123138428,
  &#39;LightGBM_BAG_L1&#39;: 35.923736572265625,
  &#39;RandomForestMSE_BAG_L1&#39;: 8.459296226501465,
  &#39;CatBoost_BAG_L1&#39;: 186.12697100639343,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 6.556365251541138,
  &#39;NeuralNetFastAI_BAG_L1&#39;: 82.1077229976654,
  &#39;WeightedEnsemble_L2&#39;: 0.6386940479278564,
  &#39;LightGBMXT_BAG_L2&#39;: 47.57743048667908,
  &#39;LightGBM_BAG_L2&#39;: 25.609368085861206,
  &#39;RandomForestMSE_BAG_L2&#39;: 28.340273141860962,
  &#39;CatBoost_BAG_L2&#39;: 63.77363443374634,
  &#39;ExtraTreesMSE_BAG_L2&#39;: 7.74618673324585,
  &#39;NeuralNetFastAI_BAG_L2&#39;: 32.23003172874451,
  &#39;WeightedEnsemble_L3&#39;: 0.24348139762878418},
 &#39;model_pred_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.042998313903808594,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.05234408378601074,
  &#39;LightGBMXT_BAG_L1&#39;: 7.178146123886108,
  &#39;LightGBM_BAG_L1&#39;: 1.936704397201538,
  &#39;RandomForestMSE_BAG_L1&#39;: 0.42211413383483887,
  &#39;CatBoost_BAG_L1&#39;: 0.10204577445983887,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 0.5491876602172852,
  &#39;NeuralNetFastAI_BAG_L1&#39;: 0.3161470890045166,
  &#39;WeightedEnsemble_L2&#39;: 0.0019054412841796875,
  &#39;LightGBMXT_BAG_L2&#39;: 3.519035816192627,
  &#39;LightGBM_BAG_L2&#39;: 0.39391183853149414,
  &#39;RandomForestMSE_BAG_L2&#39;: 0.48110461235046387,
  &#39;CatBoost_BAG_L2&#39;: 0.04786419868469238,
  &#39;ExtraTreesMSE_BAG_L2&#39;: 0.7180435657501221,
  &#39;NeuralNetFastAI_BAG_L2&#39;: 0.32416415214538574,
  &#39;WeightedEnsemble_L3&#39;: 0.00046539306640625},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;KNeighborsDist_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;LightGBMXT_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;ExtraTreesMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;NeuralNetFastAI_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBMXT_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;ExtraTreesMSE_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;NeuralNetFastAI_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                      model   score_val  pred_time_val    fit_time  \
 0      WeightedEnsemble_L3  -52.716107      12.193213  440.246144   
 1   RandomForestMSE_BAG_L2  -53.286673      11.080792  406.647108   
 2     ExtraTreesMSE_BAG_L2  -53.855148      11.317731  386.053022   
 3          LightGBM_BAG_L2  -54.933963      10.993599  403.916203   
 4          CatBoost_BAG_L2  -55.560858      10.647552  442.080469   
 5        LightGBMXT_BAG_L2  -60.264888      14.118723  425.884265   
 6    KNeighborsDist_BAG_L1  -84.125061       0.052344    0.048824   
 7      WeightedEnsemble_L2  -84.125061       0.054250    0.687518   
 8   NeuralNetFastAI_BAG_L2  -91.361718      10.923852  410.536867   
 9    KNeighborsUnif_BAG_L1 -101.546199       0.042998    0.053868   
 10  RandomForestMSE_BAG_L1 -116.548359       0.422114    8.459296   
 11    ExtraTreesMSE_BAG_L1 -124.600676       0.549188    6.556365   
 12         CatBoost_BAG_L1 -130.485451       0.102046  186.126971   
 13         LightGBM_BAG_L1 -131.054162       1.936704   35.923737   
 14       LightGBMXT_BAG_L1 -131.460909       7.178146   59.030051   
 15  NeuralNetFastAI_BAG_L1 -137.860780       0.316147   82.107723   
 
     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                 0.000465           0.243481            3       True   
 1                 0.481105          28.340273            2       True   
 2                 0.718044           7.746187            2       True   
 3                 0.393912          25.609368            2       True   
 4                 0.047864          63.773634            2       True   
 5                 3.519036          47.577430            2       True   
 6                 0.052344           0.048824            1       True   
 7                 0.001905           0.638694            2       True   
 8                 0.324164          32.230032            2       True   
 9                 0.042998           0.053868            1       True   
 10                0.422114           8.459296            1       True   
 11                0.549188           6.556365            1       True   
 12                0.102046         186.126971            1       True   
 13                1.936704          35.923737            1       True   
 14                7.178146          59.030051            1       True   
 15                0.316147          82.107723            1       True   
 
     fit_order  
 0          16  
 1          12  
 2          14  
 3          11  
 4          13  
 5          10  
 6           2  
 7           9  
 8          15  
 9           1  
 10          5  
 11          7  
 12          6  
 13          4  
 14          3  
 15          8  }</code></pre>
</div>
</div>
<section id="create-predictions-from-test-dataset" class="cell markdown"
id="eQMJ0LLFFdT2">
<h3>Create predictions from test dataset</h3>
</section>
<div class="cell code" data-execution_count="14"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="0sGhSHWiFdT2" data-outputId="f9872859-dbce-4a2c-88df-2c830f2e90ed">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> predictor.predict(test)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>predictions.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="14">
<pre><code>0    23.494125
1    40.768330
2    44.889057
3    47.639370
4    50.851894
Name: count, dtype: float32</code></pre>
</div>
</div>
<section
id="note-kaggle-will-reject-the-submission-if-we-dont-set-everything-to-be--0"
class="cell markdown" id="fmlNZUpIFdT3">
<h4>NOTE: Kaggle will reject the submission if we don't set everything
to be &gt; 0.</h4>
</section>
<div class="cell code" data-execution_count="15"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="pSACRCKWFdT3" data-outputId="62cd8950-6af6-4f3d-d412-26a7d5f65427">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Describe the `predictions` series to see if there are any negative values</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>predictions.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="15">
<pre><code>count    6493.000000
mean      100.475655
std        90.042526
min         2.928544
25%        20.472351
50%        63.278301
75%       168.610107
max       364.604309
Name: count, dtype: float64</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="16"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="NNvOfbXFFdT3" data-outputId="7c445e64-6a3c-4dd8-d382-6739f1b6e3f8">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How many negative values do we have?</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>predictions[predictions<span class="op">&lt;</span><span class="dv">0</span>]</span></code></pre></div>
<div class="output execute_result" data-execution_count="16">
<pre><code>Series([], Name: count, dtype: float32)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="17" id="pxFyypNxFdT4">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set them to zero</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>predictions[predictions<span class="op">&lt;</span><span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
</div>
<section id="set-predictions-to-submission-dataframe-save-and-submit"
class="cell markdown" id="C1fDMxn8FdT4">
<h3>Set predictions to submission dataframe, save, and submit</h3>
</section>
<div class="cell code" data-execution_count="18" id="BmaGm22YFdT5">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>submission[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> predictions</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>submission.to_csv(<span class="st">&quot;submission.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="19"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="2VNkRbUvFdT5" data-outputId="186dbef7-e2b3-4905-ec31-b68a347484e1">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission.csv <span class="op">-</span>m <span class="st">&quot;first raw submission&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100% 188k/188k [00:01&lt;00:00, 182kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<section
id="view-submission-via-the-command-line-or-in-the-web-browser-under-the-competitions-page---my-submissions"
class="cell markdown" id="I8P5Z4CxFdT5">
<h4>View submission via the command line or in the web browser under the
competition's page - <code>My Submissions</code></h4>
</section>
<div class="cell code" data-execution_count="20"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="0c8UFwWEFdT6" data-outputId="5810db22-b457-4bc3-add0-7add60dd22d6">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName        date                 description           status    publicScore  privateScore  
--------------  -------------------  --------------------  --------  -----------  ------------  
submission.csv  2023-06-11 11:32:37  first raw submission  complete  1.80994      1.80994       
</code></pre>
</div>
</div>
<section id="initial-score-of-180994" class="cell markdown"
id="xHGeDvBjFdT6">
<h4>Initial score of <code>1.80994</code></h4>
</section>
<section
id="step-4-exploratory-data-analysis-and-creating-an-additional-feature"
class="cell markdown" id="gkXskUQvFdT6">
<h2>Step 4: Exploratory Data Analysis and Creating an additional
feature</h2>
<ul>
<li>Any additional feature will do, but a great suggestion would be to
separate out the datetime into hour, day, or month parts.</li>
</ul>
</section>
<div class="cell code" data-execution_count="21"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="xDwvXODnFdUC" data-outputId="3b1dd387-1ef4-4025-e1d1-7ff83b77eb2c">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a histogram of all features to show the distribution of each one relative to the data. This is part of the exploritory data analysis</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>train.hist(figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">20</span>))</span></code></pre></div>
<div class="output execute_result" data-execution_count="21">
<pre><code>array([[&lt;Axes: title={&#39;center&#39;: &#39;datetime&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;season&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;holiday&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;workingday&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;weather&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;temp&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;atemp&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;humidity&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;windspeed&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;casual&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;registered&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;count&#39;}&gt;]], dtype=object)</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_75d63ff48b5a41a4ba1bbf8f285e7bdc/24d36aa6d9aebf07e12cbd1336d82d62d7e80a5d.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="22" id="rSLr3NnpFdUC">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a new feature</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;year&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;datetime&#39;</span>].dt.year</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;month&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;datetime&#39;</span>].dt.month</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;day&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;datetime&#39;</span>].dt.day</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;hour&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;datetime&#39;</span>].dt.hour</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;year&#39;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>].dt.year</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;month&#39;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>].dt.month</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;day&#39;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>].dt.day</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;hour&#39;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>].dt.hour</span></code></pre></div>
</div>
<section
id="make-category-types-for-these-so-models-know-they-are-not-just-numbers"
class="cell markdown" id="k4Ky_uSsFdUD">
<h2>Make category types for these so models know they are not just
numbers</h2>
<ul>
<li>AutoGluon originally sees these as ints, but in reality they are int
representations of a category.</li>
<li>Setting the dtype to category will classify these as categories in
AutoGluon.</li>
</ul>
</section>
<div class="cell code" data-execution_count="23" id="fXkqH0z2FdUD">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&quot;season&quot;</span>] <span class="op">=</span> train[<span class="st">&quot;season&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&quot;weather&quot;</span>] <span class="op">=</span> train[<span class="st">&quot;weather&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&quot;season&quot;</span>] <span class="op">=</span> test[<span class="st">&quot;season&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&quot;weather&quot;</span>] <span class="op">=</span> test[<span class="st">&quot;weather&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="24"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:250}"
id="faJK9WmqFdUE" data-outputId="bea9fc54-63fd-41db-873d-703ea43d9d93">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View are new feature</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>train.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="24">

  <div id="df-6d82fb91-291d-4fdd-96a1-4cdde37f9b77">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>hour</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-01 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0</td>
      <td>3</td>
      <td>13</td>
      <td>16</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-01 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>8</td>
      <td>32</td>
      <td>40</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-01 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>5</td>
      <td>27</td>
      <td>32</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-01 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>3</td>
      <td>10</td>
      <td>13</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-01 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-6d82fb91-291d-4fdd-96a1-4cdde37f9b77')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-6d82fb91-291d-4fdd-96a1-4cdde37f9b77 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-6d82fb91-291d-4fdd-96a1-4cdde37f9b77');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="25"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="7bM1kZSxFdUF" data-outputId="9af15885-61f0-4d35-a9e4-2165c36eae36">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View histogram of all features again now with the hour feature</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>train.hist(figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">20</span>))</span></code></pre></div>
<div class="output execute_result" data-execution_count="25">
<pre><code>array([[&lt;Axes: title={&#39;center&#39;: &#39;datetime&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;holiday&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;workingday&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;temp&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;atemp&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;humidity&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;windspeed&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;casual&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;registered&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;count&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;year&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;month&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;day&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;hour&#39;}&gt;, &lt;Axes: &gt;, &lt;Axes: &gt;]],
      dtype=object)</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_75d63ff48b5a41a4ba1bbf8f285e7bdc/f73b59ea4b91239040affa56ca729cee2072033a.png" /></p>
</div>
</div>
<section
id="step-5-rerun-the-model-with-the-same-settings-as-before-just-with-more-features"
class="cell markdown" id="vnMz2V20FdUF">
<h2>Step 5: Rerun the model with the same settings as before, just with
more features</h2>
</section>
<div class="cell code" data-execution_count="26"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="u63WIqYVFdUG" data-outputId="0a160889-4573-4f93-ca02-51f2c312d0b3">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>predictor_new_features <span class="op">=</span> TabularPredictor(label <span class="op">=</span> <span class="st">&#39;count&#39;</span>, </span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>                                          problem_type <span class="op">=</span> <span class="st">&#39;regression&#39;</span>,</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>                                          eval_metric <span class="op">=</span> <span class="st">&#39;root_mean_squared_error&#39;</span>, </span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>                                          learner_kwargs <span class="op">=</span> {<span class="st">&#39;ignored_columns&#39;</span>: [<span class="st">&#39;casual&#39;</span>, <span class="st">&#39;registered&#39;</span>]}).fit(train_data <span class="op">=</span> train, </span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>                                                                                                              time_limit <span class="op">=</span> <span class="dv">600</span>, </span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>                                                                                                              presets <span class="op">=</span> <span class="st">&#39;best_quality&#39;</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230611_114136/&quot;
Presets specified: [&#39;best_quality&#39;]
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230611_114136/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023
Train Data Rows:    10886
Train Data Columns: 15
Label Column: count
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Dropping user-specified ignored columns: [&#39;casual&#39;, &#39;registered&#39;]
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    10892.22 MB
	Train Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 3 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;category&#39;, []) : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 7 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;humidity&#39;, &#39;year&#39;, &#39;month&#39;, ...]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.1s = Fit runtime
	13 features in original data used to generate 17 features in processed data.
	Train Data (Processed) Memory Usage: 1.1 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.21s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
Fitting 11 L1 models ...
Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.76s of the 599.78s of remaining time.
	-101.5462	 = Validation score   (-root_mean_squared_error)
	0.06s	 = Training   runtime
	0.06s	 = Validation runtime
Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 399.58s of the 599.61s of remaining time.
	-84.1251	 = Validation score   (-root_mean_squared_error)
	0.05s	 = Training   runtime
	0.05s	 = Validation runtime
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 399.45s of the 599.48s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-34.346	 = Validation score   (-root_mean_squared_error)
	76.25s	 = Training   runtime
	9.91s	 = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 317.49s of the 517.51s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-33.9173	 = Validation score   (-root_mean_squared_error)
	40.96s	 = Training   runtime
	3.05s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 269.95s of the 469.97s of remaining time.
	-38.3061	 = Validation score   (-root_mean_squared_error)
	11.85s	 = Training   runtime
	0.64s	 = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 256.35s of the 456.37s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-33.811	 = Validation score   (-root_mean_squared_error)
	219.45s	 = Training   runtime
	0.3s	 = Validation runtime
Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 32.2s of the 232.22s of remaining time.
	-38.3116	 = Validation score   (-root_mean_squared_error)
	5.07s	 = Training   runtime
	0.62s	 = Validation runtime
Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 25.01s of the 225.03s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-109.6208	 = Validation score   (-root_mean_squared_error)
	47.08s	 = Training   runtime
	0.7s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 173.3s of remaining time.
	-32.1069	 = Validation score   (-root_mean_squared_error)
	0.53s	 = Training   runtime
	0.0s	 = Validation runtime
Fitting 9 L2 models ...
Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 172.72s of the 172.71s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-31.2824	 = Validation score   (-root_mean_squared_error)
	27.63s	 = Training   runtime
	0.75s	 = Validation runtime
Fitting model: LightGBM_BAG_L2 ... Training model for up to 140.8s of the 140.78s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-30.6395	 = Validation score   (-root_mean_squared_error)
	23.97s	 = Training   runtime
	0.27s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 113.61s of the 113.6s of remaining time.
	-31.6109	 = Validation score   (-root_mean_squared_error)
	36.76s	 = Training   runtime
	0.49s	 = Validation runtime
Fitting model: CatBoost_BAG_L2 ... Training model for up to 75.44s of the 75.43s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-30.6089	 = Validation score   (-root_mean_squared_error)
	68.93s	 = Training   runtime
	0.12s	 = Validation runtime
Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 3.09s of the 3.07s of remaining time.
	-31.445	 = Validation score   (-root_mean_squared_error)
	10.31s	 = Training   runtime
	0.47s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -8.36s of remaining time.
	-30.3159	 = Validation score   (-root_mean_squared_error)
	0.2s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 608.6s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230611_114136/&quot;)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="27"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="GCuDkYSHFdUG" data-outputId="d9898d95-ab6f-4702-d3a4-218cdb6402cf">
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>predictor_new_features.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0      WeightedEnsemble_L3  -30.315906      16.971429  558.249156                0.000493           0.203374            3       True         15
1          CatBoost_BAG_L2  -30.608889      15.454849  469.689962                0.121254          68.931409            2       True         13
2          LightGBM_BAG_L2  -30.639497      15.604241  424.725097                0.270646          23.966544            2       True         11
3        LightGBMXT_BAG_L2  -31.282362      16.086130  428.388501                0.752535          27.629948            2       True         10
4     ExtraTreesMSE_BAG_L2  -31.444974      15.806391  411.071690                0.472796          10.313136            2       True         14
5   RandomForestMSE_BAG_L2  -31.610878      15.826500  437.517881                0.492905          36.759328            2       True         12
6      WeightedEnsemble_L2  -32.106880      13.951785  349.076751                0.000874           0.533175            2       True          9
7          CatBoost_BAG_L1  -33.811013       0.304794  219.445981                0.304794         219.445981            1       True          6
8          LightGBM_BAG_L1  -33.917339       3.051182   40.957435                3.051182          40.957435            1       True          4
9        LightGBMXT_BAG_L1  -34.345997       9.907585   76.247536                9.907585          76.247536            1       True          3
10  RandomForestMSE_BAG_L1  -38.306120       0.635524   11.845095                0.635524          11.845095            1       True          5
11    ExtraTreesMSE_BAG_L1  -38.311570       0.617694    5.066866                0.617694           5.066866            1       True          7
12   KNeighborsDist_BAG_L1  -84.125061       0.051826    0.047529                0.051826           0.047529            1       True          2
13   KNeighborsUnif_BAG_L1 -101.546199       0.062309    0.063760                0.062309           0.063760            1       True          1
14  NeuralNetFastAI_BAG_L1 -109.620804       0.702681   47.084351                0.702681          47.084351            1       True          8
Number of models trained: 15
Types of models trained:
{&#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_RF&#39;, &#39;StackerEnsembleModel_XT&#39;, &#39;StackerEnsembleModel_KNN&#39;, &#39;StackerEnsembleModel_LGB&#39;, &#39;StackerEnsembleModel_NNFastAiTabular&#39;, &#39;StackerEnsembleModel_CatBoost&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="27">
<pre><code>{&#39;model_types&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_XT&#39;,
  &#39;NeuralNetFastAI_BAG_L1&#39;: &#39;StackerEnsembleModel_NNFastAiTabular&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L2&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;ExtraTreesMSE_BAG_L2&#39;: &#39;StackerEnsembleModel_XT&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: -101.54619908446061,
  &#39;KNeighborsDist_BAG_L1&#39;: -84.12506123181602,
  &#39;LightGBMXT_BAG_L1&#39;: -34.34599701170154,
  &#39;LightGBM_BAG_L1&#39;: -33.91733862651761,
  &#39;RandomForestMSE_BAG_L1&#39;: -38.30612025079756,
  &#39;CatBoost_BAG_L1&#39;: -33.81101281028236,
  &#39;ExtraTreesMSE_BAG_L1&#39;: -38.31157013220686,
  &#39;NeuralNetFastAI_BAG_L1&#39;: -109.62080352549414,
  &#39;WeightedEnsemble_L2&#39;: -32.10688040489621,
  &#39;LightGBMXT_BAG_L2&#39;: -31.282361695409747,
  &#39;LightGBM_BAG_L2&#39;: -30.63949740057522,
  &#39;RandomForestMSE_BAG_L2&#39;: -31.610877727580913,
  &#39;CatBoost_BAG_L2&#39;: -30.60888896555806,
  &#39;ExtraTreesMSE_BAG_L2&#39;: -31.444974175518002,
  &#39;WeightedEnsemble_L3&#39;: -30.315906279512117},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_114136/models/KNeighborsUnif_BAG_L1/&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_114136/models/KNeighborsDist_BAG_L1/&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_114136/models/LightGBMXT_BAG_L1/&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_114136/models/LightGBM_BAG_L1/&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_114136/models/RandomForestMSE_BAG_L1/&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_114136/models/CatBoost_BAG_L1/&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_114136/models/ExtraTreesMSE_BAG_L1/&#39;,
  &#39;NeuralNetFastAI_BAG_L1&#39;: &#39;AutogluonModels/ag-20230611_114136/models/NeuralNetFastAI_BAG_L1/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230611_114136/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;AutogluonModels/ag-20230611_114136/models/LightGBMXT_BAG_L2/&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;AutogluonModels/ag-20230611_114136/models/LightGBM_BAG_L2/&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;AutogluonModels/ag-20230611_114136/models/RandomForestMSE_BAG_L2/&#39;,
  &#39;CatBoost_BAG_L2&#39;: &#39;AutogluonModels/ag-20230611_114136/models/CatBoost_BAG_L2/&#39;,
  &#39;ExtraTreesMSE_BAG_L2&#39;: &#39;AutogluonModels/ag-20230611_114136/models/ExtraTreesMSE_BAG_L2/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230611_114136/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.06375956535339355,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.04752945899963379,
  &#39;LightGBMXT_BAG_L1&#39;: 76.24753594398499,
  &#39;LightGBM_BAG_L1&#39;: 40.95743465423584,
  &#39;RandomForestMSE_BAG_L1&#39;: 11.84509539604187,
  &#39;CatBoost_BAG_L1&#39;: 219.44598126411438,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 5.066866397857666,
  &#39;NeuralNetFastAI_BAG_L1&#39;: 47.0843505859375,
  &#39;WeightedEnsemble_L2&#39;: 0.5331747531890869,
  &#39;LightGBMXT_BAG_L2&#39;: 27.629948139190674,
  &#39;LightGBM_BAG_L2&#39;: 23.966544151306152,
  &#39;RandomForestMSE_BAG_L2&#39;: 36.75932765007019,
  &#39;CatBoost_BAG_L2&#39;: 68.93140888214111,
  &#39;ExtraTreesMSE_BAG_L2&#39;: 10.313136339187622,
  &#39;WeightedEnsemble_L3&#39;: 0.20337367057800293},
 &#39;model_pred_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.06230902671813965,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.051825523376464844,
  &#39;LightGBMXT_BAG_L1&#39;: 9.907585144042969,
  &#39;LightGBM_BAG_L1&#39;: 3.0511817932128906,
  &#39;RandomForestMSE_BAG_L1&#39;: 0.6355242729187012,
  &#39;CatBoost_BAG_L1&#39;: 0.3047940731048584,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 0.6176941394805908,
  &#39;NeuralNetFastAI_BAG_L1&#39;: 0.7026808261871338,
  &#39;WeightedEnsemble_L2&#39;: 0.0008738040924072266,
  &#39;LightGBMXT_BAG_L2&#39;: 0.752535343170166,
  &#39;LightGBM_BAG_L2&#39;: 0.2706460952758789,
  &#39;RandomForestMSE_BAG_L2&#39;: 0.4929053783416748,
  &#39;CatBoost_BAG_L2&#39;: 0.12125420570373535,
  &#39;ExtraTreesMSE_BAG_L2&#39;: 0.4727964401245117,
  &#39;WeightedEnsemble_L3&#39;: 0.0004928112030029297},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;KNeighborsDist_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;LightGBMXT_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;ExtraTreesMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;NeuralNetFastAI_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBMXT_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;ExtraTreesMSE_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                      model   score_val  pred_time_val    fit_time  \
 0      WeightedEnsemble_L3  -30.315906      16.971429  558.249156   
 1          CatBoost_BAG_L2  -30.608889      15.454849  469.689962   
 2          LightGBM_BAG_L2  -30.639497      15.604241  424.725097   
 3        LightGBMXT_BAG_L2  -31.282362      16.086130  428.388501   
 4     ExtraTreesMSE_BAG_L2  -31.444974      15.806391  411.071690   
 5   RandomForestMSE_BAG_L2  -31.610878      15.826500  437.517881   
 6      WeightedEnsemble_L2  -32.106880      13.951785  349.076751   
 7          CatBoost_BAG_L1  -33.811013       0.304794  219.445981   
 8          LightGBM_BAG_L1  -33.917339       3.051182   40.957435   
 9        LightGBMXT_BAG_L1  -34.345997       9.907585   76.247536   
 10  RandomForestMSE_BAG_L1  -38.306120       0.635524   11.845095   
 11    ExtraTreesMSE_BAG_L1  -38.311570       0.617694    5.066866   
 12   KNeighborsDist_BAG_L1  -84.125061       0.051826    0.047529   
 13   KNeighborsUnif_BAG_L1 -101.546199       0.062309    0.063760   
 14  NeuralNetFastAI_BAG_L1 -109.620804       0.702681   47.084351   
 
     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                 0.000493           0.203374            3       True   
 1                 0.121254          68.931409            2       True   
 2                 0.270646          23.966544            2       True   
 3                 0.752535          27.629948            2       True   
 4                 0.472796          10.313136            2       True   
 5                 0.492905          36.759328            2       True   
 6                 0.000874           0.533175            2       True   
 7                 0.304794         219.445981            1       True   
 8                 3.051182          40.957435            1       True   
 9                 9.907585          76.247536            1       True   
 10                0.635524          11.845095            1       True   
 11                0.617694           5.066866            1       True   
 12                0.051826           0.047529            1       True   
 13                0.062309           0.063760            1       True   
 14                0.702681          47.084351            1       True   
 
     fit_order  
 0          15  
 1          13  
 2          11  
 3          10  
 4          14  
 5          12  
 6           9  
 7           6  
 8           4  
 9           3  
 10          5  
 11          7  
 12          2  
 13          1  
 14          8  }</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="28" id="K4BMJgO8FdUH">
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember to set all negative values to zero</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>predictions_new <span class="op">=</span> predictor_new_features.predict(test)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>predictions_new[predictions_new<span class="op">&lt;</span><span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="29" id="_DuQd58ZFdUH">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same submitting predictions</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>submission_new_features <span class="op">=</span> pd.read_csv(<span class="st">&quot;sampleSubmission.csv&quot;</span>, parse_dates<span class="op">=</span>[<span class="st">&quot;datetime&quot;</span>])</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>submission_new_features[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> predictions_new</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>submission_new_features.to_csv(<span class="st">&quot;submission_new_features.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="30"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="Jmv1V5aTFdUI" data-outputId="974ad3a9-b523-4421-985c-201abed4ca54">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission_new_features.csv <span class="op">-</span>m <span class="st">&quot;new features&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100% 188k/188k [00:02&lt;00:00, 90.2kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="31"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="lUSIDTIaFdUI" data-outputId="c1291eac-c71a-4e56-df87-971a96cd871a">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description           status    publicScore  privateScore  
---------------------------  -------------------  --------------------  --------  -----------  ------------  
submission_new_features.csv  2023-06-11 11:56:18  new features          complete  0.66320      0.66320       
submission.csv               2023-06-11 11:32:37  first raw submission  complete  1.80994      1.80994       
</code></pre>
</div>
</div>
<section id="new-score-of-066320" class="cell markdown"
id="ZSfswDDqFdUJ">
<h4>New Score of <code>0.66320</code></h4>
</section>
<section id="step-6-hyper-parameter-optimization" class="cell markdown"
id="gt2vmr3yFdUJ">
<h2>Step 6: Hyper parameter optimization</h2>
<ul>
<li>There are many options for hyper parameter optimization.</li>
<li>Options are to change the AutoGluon higher level parameters or the
individual model hyperparameters.</li>
<li>The hyperparameters of the models themselves that are in AutoGluon.
Those need the <code>hyperparameter</code> and
<code>hyperparameter_tune_kwargs</code> arguments.</li>
</ul>
</section>
<div class="cell code" data-execution_count="32"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000,&quot;referenced_widgets&quot;:[&quot;88dde2e9ee684797b933d07b37f553fa&quot;,&quot;078c71cecfa44b2da816ad2537070036&quot;,&quot;2b85186c6c0d46329dac497d6981c511&quot;,&quot;7574ef3b8837472998ac411e011870a4&quot;,&quot;dbb2b495da014bc59551627df4201363&quot;,&quot;1eefca111f264e8093a887904b6fe6c0&quot;,&quot;8fc70d5a5b4a471d93440c1a2a9b9522&quot;,&quot;9f97a98bdf0e458099fef899fdbf63ec&quot;,&quot;ea68bc7076134f5a8041d0ade5c2b5a1&quot;,&quot;5cc1b7697470499496cc52b53f17c4a1&quot;,&quot;c6980dc39d164169b552fc3811c36307&quot;,&quot;8a403a597973441d98a850134a6e2699&quot;,&quot;fe6a574ddf954be5905f00f17469aea5&quot;,&quot;4d20c191fb2b477db21f325ccd54e1bf&quot;,&quot;0b9b26b4726943f19d229178558e4bb1&quot;,&quot;8e45c81da17d45f783153c083af65141&quot;,&quot;6a03644fa2f4455f9e165b563fea9e3e&quot;,&quot;c5662006107d473fab53bca02b925a5e&quot;,&quot;0c561ceff65c4c6389cd3af9898c7d84&quot;,&quot;bb565ec6ff4249a2baf5ee95ec2f743e&quot;,&quot;5029eeda91d9426eaac4c4f1811322c2&quot;,&quot;13e4ec58d41b482880304932958baad7&quot;,&quot;4f736012113d474f864da8f221b57098&quot;,&quot;4d45c3853f954a93b2867c63df8c3554&quot;,&quot;042b42bcd400436091cdcd5d4d10384f&quot;,&quot;deca127db09748d2a8bb7e4bc8ce0990&quot;,&quot;1a51d5e28a3547e2b7276a5540d6d073&quot;,&quot;356f87317c964180968632904ac00fb1&quot;,&quot;82ebf47bcd93403980295689b3c80f3d&quot;,&quot;18f5e48962b94d51be85b9f03a6bf83f&quot;,&quot;52400489caed4e89b0d42b3730e2f79e&quot;,&quot;6bda440f744249c195aed4a8d36c0c82&quot;,&quot;48cd9a47aae54bb4a70427b06a7f24e5&quot;,&quot;1da20097119449d48297c8d9bde08c77&quot;,&quot;7e89c5c1e02741889f1ff19e37ef6f0d&quot;,&quot;51260835ad614a46b22ed34718aca28e&quot;,&quot;453ecd0134cf4773918c9222914c4608&quot;,&quot;c17c3af181334babb8b20dbcfc953c2b&quot;,&quot;dba79162f1c64681ab58e719735ce063&quot;,&quot;fcf66d8c9aa645e58729ae6f83dfe98f&quot;,&quot;a1c4ce61e6df45b595e2ff90f3d73fe9&quot;,&quot;52c197129ada4edcb23b941ebda41f5a&quot;,&quot;69ddc99cf43646629c5aba1584fa69d7&quot;,&quot;ae1086d93bd44c3681910070edb601fb&quot;]}"
id="qseR-zI9FdUK" data-outputId="ff65de6b-0310-437f-cd3b-047cae5f6e6a">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autogluon.core <span class="im">as</span> ag</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>nn_options <span class="op">=</span> {<span class="st">&#39;num_epochs&#39;</span>: <span class="dv">9</span>, <span class="co">#number of epochs used in training</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>              <span class="st">&#39;learning_rate&#39;</span>: ag.space.Real(<span class="fl">1e-4</span>, <span class="fl">1e-2</span>, default<span class="op">=</span><span class="fl">5e-4</span>, log<span class="op">=</span><span class="va">True</span>), <span class="co">#learning rate (for real hyperparameters)</span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>              <span class="st">&#39;activation&#39;</span>: ag.space.Categorical(<span class="st">&#39;relu&#39;</span>, <span class="st">&#39;softrelu&#39;</span>, <span class="st">&#39;tanh&#39;</span>),  <span class="co"># activation functions (for categorical hyperparameters)</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>              <span class="st">&#39;layers&#39;</span>: ag.space.Categorical([<span class="dv">100</span>], [<span class="dv">1000</span>], [<span class="dv">200</span>, <span class="dv">100</span>], [<span class="dv">300</span>, <span class="dv">200</span>, <span class="dv">100</span>]), <span class="co">#layers (for categorical hyperparamters)</span></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>              <span class="st">&#39;dropout_prob&#39;</span>: ag.space.Real(<span class="fl">0.0</span>, <span class="fl">0.5</span>, default<span class="op">=</span><span class="fl">0.1</span>),  <span class="co"># dropout probability (for real hyperparameters)</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>              }</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>gbm_options <span class="op">=</span> {<span class="st">&#39;num_boost_round&#39;</span>: <span class="dv">100</span>, <span class="co">#number of boosting rounds</span></span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>               <span class="st">&#39;num_leaves&#39;</span>: ag.space.Int(lower<span class="op">=</span><span class="dv">26</span>, upper<span class="op">=</span><span class="dv">66</span>, default<span class="op">=</span><span class="dv">36</span>), <span class="co">#number of leaves in hyperparamater tree</span></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a>               }</span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a>hyperparameters <span class="op">=</span> {<span class="st">&#39;GBM&#39;</span>: gbm_options,</span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a>                   <span class="st">&#39;NN&#39;</span>: nn_options, <span class="co">#for hyperparameters of each model type</span></span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a>                   }</span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a>hyperparameter_tune_kwargs <span class="op">=</span> {<span class="st">&#39;num_trials&#39;</span>: <span class="dv">2</span>, <span class="co">#2 different hyperparameter config for each model</span></span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a>                              <span class="st">&#39;scheduler&#39;</span> : <span class="st">&#39;local&#39;</span>,</span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a>                              <span class="st">&#39;searcher&#39;</span>: <span class="st">&#39;auto&#39;</span>,</span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a>                              }</span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a>predictor_new_hpo <span class="op">=</span> TabularPredictor(label <span class="op">=</span> <span class="st">&#39;count&#39;</span>,</span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a>                                     eval_metric <span class="op">=</span> <span class="st">&#39;root_mean_squared_error&#39;</span>, </span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a>                                     learner_kwargs <span class="op">=</span> {<span class="st">&#39;ignored_columns&#39;</span>: [<span class="st">&#39;casual&#39;</span>, <span class="st">&#39;registered&#39;</span>]}).fit(train_data <span class="op">=</span> train, </span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a>                                                                                                         time_limit <span class="op">=</span> <span class="dv">600</span>, </span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a>                                                                                                         presets <span class="op">=</span> <span class="st">&#39;best_quality&#39;</span>, </span>
<span id="cb52-27"><a href="#cb52-27" aria-hidden="true" tabindex="-1"></a>                                                                                                         hyperparameters <span class="op">=</span> hyperparameters, </span>
<span id="cb52-28"><a href="#cb52-28" aria-hidden="true" tabindex="-1"></a>                                                                                                         hyperparameter_tune_kwargs <span class="op">=</span> hyperparameter_tune_kwargs,</span>
<span id="cb52-29"><a href="#cb52-29" aria-hidden="true" tabindex="-1"></a>                                                                                                         )</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230611_121414/&quot;
Presets specified: [&#39;best_quality&#39;]
Warning: hyperparameter tuning is currently experimental and may cause the process to hang.
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230611_121414/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023
Train Data Rows:    10886
Train Data Columns: 15
Label Column: count
Preprocessing data ...
AutoGluon infers your prediction problem is: &#39;regression&#39; (because dtype of label-column == int and many unique label-values observed).
	Label info (max, min, mean, stddev): (977, 1, 191.57413, 181.14445)
	If &#39;regression&#39; is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: [&#39;binary&#39;, &#39;multiclass&#39;, &#39;regression&#39;])
Using Feature Generators to preprocess the data ...
Dropping user-specified ignored columns: [&#39;casual&#39;, &#39;registered&#39;]
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    10813.71 MB
	Train Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 3 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;category&#39;, []) : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 7 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;humidity&#39;, &#39;year&#39;, &#39;month&#39;, ...]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.1s = Fit runtime
	13 features in original data used to generate 17 features in processed data.
	Train Data (Processed) Memory Usage: 1.1 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.17s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
	WARNING: &quot;NN&quot; model has been deprecated in v0.4.0 and renamed to &quot;NN_MXNET&quot;. Starting in v0.6.0, specifying &quot;NN&quot; or &quot;NN_MXNET&quot; will raise an exception. Consider instead specifying &quot;NN_TORCH&quot;.
Fitting 2 L1 models ...
Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 179.9s of the 599.83s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb54"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;88dde2e9ee684797b933d07b37f553fa&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
Fitted model: LightGBM_BAG_L1/T1 ...
	-40.2554	 = Validation score   (-root_mean_squared_error)
	22.87s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T2 ...
	-38.8609	 = Validation score   (-root_mean_squared_error)
	25.08s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: NeuralNetMXNet_BAG_L1 ... Tuning model for up to 179.9s of the 551.79s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb56"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8a403a597973441d98a850134a6e2699&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=25853, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=25853, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-06-11 12:15:11,424	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=25854, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=25954, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=25954, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L1... Skipping this model.
Repeating k-fold bagging: 2/20
Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 334.82s of the 534.86s of remaining time.
	Fitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-06-11 12:15:21,049	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
	-39.7819	 = Validation score   (-root_mean_squared_error)
	42.61s	 = Training   runtime
	0.14s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 311.47s of the 511.51s of remaining time.
	Fitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy
	-38.487	 = Validation score   (-root_mean_squared_error)
	44.61s	 = Training   runtime
	0.16s	 = Validation runtime
Repeating k-fold bagging: 3/20
Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 288.79s of the 488.83s of remaining time.
	Fitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy
	-39.6161	 = Validation score   (-root_mean_squared_error)
	62.16s	 = Training   runtime
	0.38s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 266.09s of the 466.13s of remaining time.
	Fitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy
	-38.3259	 = Validation score   (-root_mean_squared_error)
	63.89s	 = Training   runtime
	0.28s	 = Validation runtime
Repeating k-fold bagging: 4/20
Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 243.61s of the 443.65s of remaining time.
	Fitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy
	-39.5522	 = Validation score   (-root_mean_squared_error)
	81.45s	 = Training   runtime
	0.57s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 221.07s of the 421.11s of remaining time.
	Fitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy
	-38.2599	 = Validation score   (-root_mean_squared_error)
	83.43s	 = Training   runtime
	0.46s	 = Validation runtime
Repeating k-fold bagging: 5/20
Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 198.29s of the 398.33s of remaining time.
	Fitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy
	-39.5237	 = Validation score   (-root_mean_squared_error)
	101.01s	 = Training   runtime
	0.72s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 175.41s of the 375.45s of remaining time.
	Fitting 8 child models (S5F1 - S5F8) | Fitting with ParallelLocalFoldFittingStrategy
	-38.2323	 = Validation score   (-root_mean_squared_error)
	104.89s	 = Training   runtime
	0.63s	 = Validation runtime
Repeating k-fold bagging: 6/20
Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 150.72s of the 350.76s of remaining time.
	Fitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy
	-39.5069	 = Validation score   (-root_mean_squared_error)
	120.83s	 = Training   runtime
	0.89s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 125.47s of the 325.51s of remaining time.
	Fitting 8 child models (S6F1 - S6F8) | Fitting with ParallelLocalFoldFittingStrategy
	-38.2296	 = Validation score   (-root_mean_squared_error)
	124.0s	 = Training   runtime
	0.75s	 = Validation runtime
Repeating k-fold bagging: 7/20
Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 103.25s of the 303.29s of remaining time.
	Fitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy
	-39.5149	 = Validation score   (-root_mean_squared_error)
	140.12s	 = Training   runtime
	1.05s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 80.78s of the 280.82s of remaining time.
	Fitting 8 child models (S7F1 - S7F8) | Fitting with ParallelLocalFoldFittingStrategy
	-38.2322	 = Validation score   (-root_mean_squared_error)
	143.17s	 = Training   runtime
	0.91s	 = Validation runtime
Completed 7/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 258.47s of remaining time.
	-38.2322	 = Validation score   (-root_mean_squared_error)
	0.1s	 = Training   runtime
	0.0s	 = Validation runtime
	WARNING: &quot;NN&quot; model has been deprecated in v0.4.0 and renamed to &quot;NN_MXNET&quot;. Starting in v0.6.0, specifying &quot;NN&quot; or &quot;NN_MXNET&quot; will raise an exception. Consider instead specifying &quot;NN_TORCH&quot;.
Fitting 2 L2 models ...
Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 116.26s of the 258.34s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb58"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;4f736012113d474f864da8f221b57098&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
Fitted model: LightGBM_BAG_L2/T1 ...
	-36.9021	 = Validation score   (-root_mean_squared_error)
	22.76s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L2/T2 ...
	-36.9623	 = Validation score   (-root_mean_squared_error)
	22.6s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: NeuralNetMXNet_BAG_L2 ... Tuning model for up to 116.26s of the 212.92s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb60"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;1da20097119449d48297c8d9bde08c77&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=30996, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=30996, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-06-11 12:20:48,824	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=31084, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=31084, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L2... Skipping this model.
Repeating k-fold bagging: 2/20
Fitting model: LightGBM_BAG_L2/T1 ... Training model for up to 199.28s of the 199.27s of remaining time.
	Fitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-06-11 12:20:56,134	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
	-36.8215	 = Validation score   (-root_mean_squared_error)
	42.49s	 = Training   runtime
	0.23s	 = Validation runtime
Fitting model: LightGBM_BAG_L2/T2 ... Training model for up to 175.51s of the 175.5s of remaining time.
	Fitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy
	-36.7366	 = Validation score   (-root_mean_squared_error)
	43.49s	 = Training   runtime
	0.11s	 = Validation runtime
Repeating k-fold bagging: 3/20
Fitting model: LightGBM_BAG_L2/T1 ... Training model for up to 151.36s of the 151.35s of remaining time.
	Fitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy
	-36.8192	 = Validation score   (-root_mean_squared_error)
	62.91s	 = Training   runtime
	0.32s	 = Validation runtime
Fitting model: LightGBM_BAG_L2/T2 ... Training model for up to 125.28s of the 125.27s of remaining time.
	Fitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy
	-36.6307	 = Validation score   (-root_mean_squared_error)
	63.03s	 = Training   runtime
	0.24s	 = Validation runtime
Repeating k-fold bagging: 4/20
Fitting model: LightGBM_BAG_L2/T1 ... Training model for up to 102.43s of the 102.42s of remaining time.
	Fitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy
	-36.7883	 = Validation score   (-root_mean_squared_error)
	82.47s	 = Training   runtime
	0.6s	 = Validation runtime
Fitting model: LightGBM_BAG_L2/T2 ... Training model for up to 79.66s of the 79.65s of remaining time.
	Fitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy
	-36.5611	 = Validation score   (-root_mean_squared_error)
	82.37s	 = Training   runtime
	0.4s	 = Validation runtime
Completed 4/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 56.93s of remaining time.
	-36.5611	 = Validation score   (-root_mean_squared_error)
	0.12s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 543.22s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230611_121414/&quot;)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="33"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="PiB4aNIIFdUN" data-outputId="4a49550b-2dde-4ad1-a07b-69c30c7d4405">
<div class="sourceCode" id="cb62"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>predictor_new_hpo.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                 model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0   LightGBM_BAG_L2/T2 -36.561051       2.356589  365.655168                0.396187          82.373635            2       True          5
1  WeightedEnsemble_L3 -36.561051       2.357328  365.777429                0.000738           0.122262            3       True          6
2   LightGBM_BAG_L2/T1 -36.788252       2.555765  365.749581                0.595363          82.468048            2       True          4
3   LightGBM_BAG_L1/T2 -38.232163       0.909772  143.165608                0.909772         143.165608            1       True          2
4  WeightedEnsemble_L2 -38.232163       0.910613  143.269412                0.000841           0.103805            2       True          3
5   LightGBM_BAG_L1/T1 -39.514896       1.050630  140.115925                1.050630         140.115925            1       True          1
Number of models trained: 6
Types of models trained:
{&#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_LGB&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="33">
<pre><code>{&#39;model_types&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBM_BAG_L2/T1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2/T2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: -39.51489645256764,
  &#39;LightGBM_BAG_L1/T2&#39;: -38.23216262692166,
  &#39;WeightedEnsemble_L2&#39;: -38.23216262692166,
  &#39;LightGBM_BAG_L2/T1&#39;: -36.788252426815234,
  &#39;LightGBM_BAG_L2/T2&#39;: -36.56105070702006,
  &#39;WeightedEnsemble_L3&#39;: -36.56105070702006},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: &#39;/content/AutogluonModels/ag-20230611_121414/models/LightGBM_BAG_L1/T1/&#39;,
  &#39;LightGBM_BAG_L1/T2&#39;: &#39;/content/AutogluonModels/ag-20230611_121414/models/LightGBM_BAG_L1/T2/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230611_121414/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBM_BAG_L2/T1&#39;: &#39;/content/AutogluonModels/ag-20230611_121414/models/LightGBM_BAG_L2/T1/&#39;,
  &#39;LightGBM_BAG_L2/T2&#39;: &#39;/content/AutogluonModels/ag-20230611_121414/models/LightGBM_BAG_L2/T2/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230611_121414/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: 140.11592483520508,
  &#39;LightGBM_BAG_L1/T2&#39;: 143.16560769081116,
  &#39;WeightedEnsemble_L2&#39;: 0.1038045883178711,
  &#39;LightGBM_BAG_L2/T1&#39;: 82.4680483341217,
  &#39;LightGBM_BAG_L2/T2&#39;: 82.37363505363464,
  &#39;WeightedEnsemble_L3&#39;: 0.12226152420043945},
 &#39;model_pred_times&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: 1.0506296157836914,
  &#39;LightGBM_BAG_L1/T2&#39;: 0.9097723960876465,
  &#39;WeightedEnsemble_L2&#39;: 0.0008406639099121094,
  &#39;LightGBM_BAG_L2/T1&#39;: 0.5953631401062012,
  &#39;LightGBM_BAG_L2/T2&#39;: 0.39618730545043945,
  &#39;WeightedEnsemble_L3&#39;: 0.0007383823394775391},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                  model  score_val  pred_time_val    fit_time  \
 0   LightGBM_BAG_L2/T2 -36.561051       2.356589  365.655168   
 1  WeightedEnsemble_L3 -36.561051       2.357328  365.777429   
 2   LightGBM_BAG_L2/T1 -36.788252       2.555765  365.749581   
 3   LightGBM_BAG_L1/T2 -38.232163       0.909772  143.165608   
 4  WeightedEnsemble_L2 -38.232163       0.910613  143.269412   
 5   LightGBM_BAG_L1/T1 -39.514896       1.050630  140.115925   
 
    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                0.396187          82.373635            2       True   
 1                0.000738           0.122262            3       True   
 2                0.595363          82.468048            2       True   
 3                0.909772         143.165608            1       True   
 4                0.000841           0.103805            2       True   
 5                1.050630         140.115925            1       True   
 
    fit_order  
 0          5  
 1          6  
 2          4  
 3          2  
 4          3  
 5          1  }</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="34" id="pCfB74CSFdUO">
<div class="sourceCode" id="cb66"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember to set all negative values to zero</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>predictions_new_hpo <span class="op">=</span> predictor_new_hpo.predict(test)</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>predictions_new_hpo[predictions_new_hpo<span class="op">&lt;</span><span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="35" id="O5aGNsopFdUP">
<div class="sourceCode" id="cb67"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same submitting predictions</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>submission_new_hpo <span class="op">=</span> pd.read_csv(<span class="st">&quot;sampleSubmission.csv&quot;</span>, parse_dates<span class="op">=</span>[<span class="st">&quot;datetime&quot;</span>])</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>submission_new_hpo[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> predictions_new_hpo</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>submission_new_hpo.to_csv(<span class="st">&quot;submission_new_hpo.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="36"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="ZGAj68a6FdUR" data-outputId="2b6d82a2-612a-4628-a6df-7299b685c604">
<div class="sourceCode" id="cb68"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission_new_hpo.csv <span class="op">-</span>m <span class="st">&quot;new features with hyperparameters&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100% 188k/188k [00:02&lt;00:00, 76.8kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="37"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="qcEnbMV5FdUR" data-outputId="d4fd6e97-c2c3-45eb-ae37-22b50d6b3d55">
<div class="sourceCode" id="cb70"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description                        status    publicScore  privateScore  
---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  
submission_new_hpo.csv       2023-06-11 12:26:16  new features with hyperparameters  complete  0.48817      0.48817       
submission_new_features.csv  2023-06-11 11:56:18  new features                       complete  0.66320      0.66320       
submission.csv               2023-06-11 11:32:37  first raw submission               complete  1.80994      1.80994       
</code></pre>
</div>
</div>
<section id="new-score-of-048817" class="cell markdown"
id="_snQsdfhFdUS">
<h4>New Score of <code>0.48817</code></h4>
</section>
<section id="step-7-write-a-report" class="cell markdown"
id="61r3oDIyFdUS">
<h2>Step 7: Write a Report</h2>
<h3 id="refer-to-the-markdown-file-for-the-full-report">Refer to the
markdown file for the full report</h3>
<h3 id="creating-plots-and-table-for-report">Creating plots and table
for report</h3>
</section>
<div class="cell code" data-execution_count="40"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:542}"
id="47JoEcJLFdUT" data-jupyter="{&quot;source_hidden&quot;:true}"
data-outputId="bef6ca83-01fe-480e-ee34-308b0582b048">
<div class="sourceCode" id="cb72"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Taking the top model score from each training run and creating a line plot to show improvement</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="co"># You can create these in the notebook and save them to PNG or use some other tool (e.g. google sheets, excel)</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> pd.DataFrame(</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;model&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;score&quot;</span>: [<span class="op">-</span><span class="fl">52.7161</span>, <span class="op">-</span><span class="fl">30.3159</span>, <span class="op">-</span><span class="fl">36.5611</span>]</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a>).plot(x<span class="op">=</span><span class="st">&quot;model&quot;</span>, y<span class="op">=</span><span class="st">&quot;score&quot;</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>)).get_figure()</span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;model_train_score.png&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_75d63ff48b5a41a4ba1bbf8f285e7bdc/2fcba6996e211202e984927e2a3dc265e5533437.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="39"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:542}"
id="5EnqXj4EFdUT" data-outputId="86732eba-3400-4303-bacf-8eacf4752a00">
<div class="sourceCode" id="cb73"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Take the 3 kaggle scores and creating a line plot to show improvement</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> pd.DataFrame(</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;test_eval&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;score&quot;</span>: [<span class="fl">1.80994</span>, <span class="fl">0.66320</span>, <span class="fl">0.48817</span>]</span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>).plot(x<span class="op">=</span><span class="st">&quot;test_eval&quot;</span>, y<span class="op">=</span><span class="st">&quot;score&quot;</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>)).get_figure()</span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;model_test_score.png&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_75d63ff48b5a41a4ba1bbf8f285e7bdc/1d60a4a496bde7a4e44924a0c380e5ff2ae36e5b.png" /></p>
</div>
</div>
<section id="hyperparameter-table" class="cell markdown"
id="Jd1PCyxbFdUU">
<h3>Hyperparameter table</h3>
</section>
<div class="cell code" data-execution_count="43"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:143}"
id="OLO17X94FdUU" data-outputId="9a1c73a8-048c-4edd-bbdb-89dbde0454fd">
<div class="sourceCode" id="cb74"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The 3 hyperparameters we tuned with the kaggle score as the result</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;model&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hpo1&quot;</span>: [<span class="st">&#39;best_quality&#39;</span>, <span class="st">&#39;best_quality&#39;</span>, <span class="st">&#39;best_quality&#39;</span>],</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hpo2&quot;</span>: [<span class="st">&#39;600s&#39;</span>, <span class="st">&#39;600s&#39;</span>, <span class="st">&#39;600s&#39;</span>],</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hpo3&quot;</span>: [<span class="st">&#39;none&#39;</span>, <span class="st">&#39;regression&#39;</span>, <span class="st">&#39;tabular auto-gluon&#39;</span>],</span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;score&quot;</span>: [<span class="fl">1.80994</span>, <span class="fl">0.66320</span>, <span class="fl">0.48817</span>]</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>})</span></code></pre></div>
<div class="output execute_result" data-execution_count="43">

  <div id="df-6551fe66-fd99-4f07-90b0-26e7b3b46b72">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>hpo1</th>
      <th>hpo2</th>
      <th>hpo3</th>
      <th>score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>initial</td>
      <td>best_quality</td>
      <td>600s</td>
      <td>none</td>
      <td>1.80994</td>
    </tr>
    <tr>
      <th>1</th>
      <td>add_features</td>
      <td>best_quality</td>
      <td>600s</td>
      <td>regression</td>
      <td>0.66320</td>
    </tr>
    <tr>
      <th>2</th>
      <td>hpo</td>
      <td>best_quality</td>
      <td>600s</td>
      <td>tabular auto-gluon</td>
      <td>0.48817</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-6551fe66-fd99-4f07-90b0-26e7b3b46b72')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-6551fe66-fd99-4f07-90b0-26e7b3b46b72 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-6551fe66-fd99-4f07-90b0-26e7b3b46b72');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
</body>
</html>
